\documentclass[12pt, a4paper]{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% dodatkowe pakiety LaTeX'a
\usepackage[OT4]{polski}
\usepackage[utf8]{inputenc}
\usepackage[top=2.5cm, bottom=2.5cm, left=2cm, right=2cm]{geometry}
\usepackage{graphicx}
\usepackage{float}
\usepackage[colorlinks=true, linkcolor=blue]{hyperref}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ustawienia globalne
<<ustawienia_globalne, echo=FALSE, warning=FALSE>>=
library(knitr)
opts_chunk$set(
  fig.path='figure/',
  fig.align='center',
  fig.pos='H',
  fig.width=5,
  fig.height=4)
@


\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% strona tytulowa


\title{Raport nr 3}
\author{Emilia Kowal [249716], Jakub Dworzański [249703]}
\maketitle
\tableofcontents


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% Zad. 1
\section{Klasyfikacja na bazie modelu regresji liniowej}

<<>>=
library(datasets)
library(ggplot2)
library(varhandle)
@

\subsection{Krótki opis zagadnienia.}
W tej sekcji będziemy zajmować się klasyfikacją opartą na modelu regresji liniowej, z wykorzystaniem metody najmniejszych kwadratów.
Analizy dokonujemy na zbiorze danych \textit{iris}:

<<echo=FALSE>>=
data(iris)
attach(iris)
head(iris)
@

Zbiór danych zawiera 150 wierszy z informacjami na temat 3 gatunków irysów: setosa, versicolor i virginica. Zmienne dostarczają nam wiedzy o szerokości i długości działki kielicha oraz płatka.
Dane nie zawierają obserwacji brakujących. \\
Po dokonaniu analizy postaramy się odpowiedzieć na pytania o:
\begin{itemize}
\item skuteczność klasyfikacji opartej na modelu regresji liniowej;
\item wpływ ilości klas na jakość predykcji;
\item maskowanie klas;
\item wpływ składników wielomianowych stopnia 2 na dokładność klasyfikacji.
\end{itemize}

\subsection{Opis eksperymentów/analiz.}

\begin{itemize}
\item W pierwszym kroku, budując model klasyfikacyjny, dokonujemy podziału zbioru danych na treningowy oraz testowy w stosunku 1:5. 
\item Następnie na podstawie danych uczących kostruujemy klasyfikator i predykujemy etykiety dla zbioru treningowego i testowego.
\item Potem dokonujemy oceny jakości modelu, wyznaczamy macierz pomyłek, przeprowadzamy analizę graficzną klasyfikatora.
\item Ostatecznie badamy wpływ składników wielomianowych stopnia 2 na dokładność modelu regresji liniowej, dodając do zbioru danych cechę Petal.Length$^2$ oraz Petal.Width$*$Sepal.Length.
\end{itemize}

\subsection{Wyniki.}

Na podstawie wykresu widzimy, iż poszczególne klasy zwierają tyle samo obiektów:
<<klasy, echo=FALSE, fig.cap="Przynależności do klas.">>=
ggplot(data=iris, aes(x=Species)) + 
  geom_bar() + labs(x="gatunek", y="liczebność gatunku")
@

\subsubsection{Analiza skuteczności modelu dla zbioru danych bez składników wielomianowych stopnia 2.}
Dokonujemy podziału zbioru danych na trengingowe oraz testowe:

<<train_test_split>>=
smp_size <- floor(0.8 * nrow(iris))
set.seed(43)
train_ind <- sample(seq_len(nrow(iris)), size=smp_size)

X_train <- cbind(rep(1,120),iris[train_ind, 1:4])
X_test <- cbind(rep(1,30),iris[-train_ind, 1:4])
Y_train <- iris[train_ind, 5]
Y_test <- iris[-train_ind, 5]
@


Konwertujemy zmienną kategoryczną na macierz wskaźnikową z wykorzystaniem funkcji \textit{to.dummy} z pakietu \textit{varhandle}:
<<konwersja>>=
Y_train_bin <- to.dummy(Y_train, prefix="species")
Y_test_bin <- to.dummy(Y_test, prefix="species")
@

Konstrujujemy klasyfikator regresji liniowej metodą najmniejszych kwadratów:

<<classifier>>=
B <- solve(t(X_train)%*%as.matrix(X_train)) %*% t(X_train) %*% as.matrix(Y_train_bin)
@
Dla zbioru testowego otrzymujemy następujące wyniki: \ref{tab:result_test}.

<<result_test, echo=FALSE>>=
Y_result <- as.matrix(X_test) %*% B
klasy <- levels(Species)
  maks.ind <- apply(Y_result, 1, FUN=function(x) which.max(x))
  prognozowane.etykietki <- klasy[maks.ind]
  rzeczywiste.etykietki <- Y_test
  
  conf_mtrx <- table(rzeczywiste.etykietki, prognozowane.etykietki)
  rownames(conf_mtrx) <- c("setosa.true", "versicolor.true", "virginica.true")
  kable(conf_mtrx,caption="Skuteczność estymatora dla danych testowych.", 
        format="latex")
  #sum(diag(conf_mtrx))/length(Y_test)
@
Dostajemy dokładność na poziomie: 73\%. \\
<<result_test_plot, echo=FALSE, fig.cap="Wizualizacja wyników dla zbioru testowego.", fig.height=6, fig.width=8>>=
matplot(Y_result, ylab="Predykcja")
  abline(v=c(10,20), lty=2, col="grey")
  legend(x="top", legend=paste(1:3,levels(Species)), col=1:3, text.col=1:3)
@
Na wykresie \ref{fig:result_test_plot} widzimy, że dominują klasy setosa i virginica, zatem wnioskujemy, iż versicolor jest zamaskowana (zdominowana) przez pozostałe dwie klasy. \\
Następnie dokonujemy analizy zgodności dla zbioru treningowego w celu uniknięcia przetrenowania modelu. Otrzymujemy następujące rezultaty: \ref{tab:result_train}.

<<result_train, echo=FALSE>>=
Y_result.train <- as.matrix(X_train) %*% B

maks.ind.train <- apply(Y_result.train, 1, FUN=function(x) which.max(x))
prognozowane.etykietki.train <- klasy[maks.ind.train]
rzeczywiste.etykietki.train <- Y_train

conf_mtrx.train <- table(rzeczywiste.etykietki.train, prognozowane.etykietki.train)
rownames(conf_mtrx.train) <- c("setosa.true", "versicolor.true", "virginica.true")

kable(conf_mtrx.train, caption="Skuteczność estymatora dla danych treningowych.", 
      format="latex")
#sum(diag(conf_mtrx.train))/length(Y_train)
@
Dostajemy zgodność na poziomie: 88\%, co mogłoby wskazywać na to, iż model jest przetrenowany. Aby uniknąć takiej sytuacji, w dalszej analizie należałoby przeprowadzić np. cross validation test, który dałby nam rzetelniejsze wyniki dla całego zbioru danych. Również fakt, iż w zbiorze nie mamy wielu rekordów, działa niekorzystnie na skuteczność modelu regresji. \\
Wyniki przedstawione graficznie:
<<result_train_plot, echo=FALSE, fig.cap="Wizualizacja wyników dla zbioru treningowego.", fig.height=6, fig.width=8>>=
matplot(Y_result.train, ylab="Predykcja")
  abline(v=c(40,80), lty=2, col="grey")
  legend(x="top", legend=paste(1:3,levels(Species)), col=1:3, text.col=1:3)
@

\subsubsection{Analiza skuteczności modelu dla zbioru danych ze składnikami wielomianowymi stopnia 2.}
Do konstrukcji drugiego modelu regresji wykorzystujemy zbiór z wyjściowymi cechami oraz zmiennymi wielomianowymi stopnia 2. 
<<new_dataset, echo=FALSE>>=
  new_iris <- cbind(Petal.Length^2, Petal.Width^2, 
                  Sepal.Length^2, Sepal.Width^2,
                  Petal.Length*Petal.Width,
                  Petal.Width*Sepal.Length,
                  Petal.Length*Sepal.Width,
                  Petal.Length*Sepal.Length,
                  Petal.Width*Sepal.Width,
                  Sepal.Length*Sepal.Width,
                  iris)

X_train_n <- cbind(rep(1,120),new_iris[train_ind, 1:14])
X_test_n <- cbind(rep(1,30),new_iris[-train_ind, 1:14])
Y_train_n <- new_iris[train_ind, 15]
Y_test_n <- new_iris[-train_ind, 15]

# konwersja zmiennej kategorycznej na macierz wskaźnikową:
Y_train_bin_n <- to.dummy(Y_train_n, prefix="species")
Y_test_bin_n <- to.dummy(Y_test_n, prefix="species")

# konstrukcja klasyfikatora regresji liniowej metodą najmniejszych kwadratów:
B1 <- solve(t(X_train_n)%*%as.matrix(X_train_n)) %*% t(X_train_n) %*% as.matrix(Y_train_bin_n)

# wartości progonozowane:
Y_result_n <- as.matrix(X_test_n) %*% B1
@

Dla estymatora, skonstruowanego w oparciu o nowy zbiór danych, dla zbioru testowego otzymujemy następujące wyniki: \ref{tab:result_test_new}.

<<result_test_new, echo=FALSE>>=
maks.ind.n <- apply(Y_result_n, 1, FUN=function(x) which.max(x))
prognozowane.etykietki.n <- klasy[maks.ind.n]
rzeczywiste.etykietki.n <- Y_test_n

conf_mtrx_n <- table(rzeczywiste.etykietki.n, prognozowane.etykietki.n)
rownames(conf_mtrx_n) <- c("setosa.true", "versicolor.true", "virginica.true")
kable(conf_mtrx_n, caption="Skuteczność nowego estymatora dla zbioru testowego.",format="latex")
@

Dostajemy zgodność na poziomie: 97\%, zatem otrzymujemy znacznie skuteczniejszy estymator dla zbioru danych ze składnikami wielomianowymi stopnia 2. 

<<result_test_new_plot, echo=FALSE, fig.cap="Wizualizacja wyników nowego estymatora dla zbioru testowego.", fig.height=6, fig.width=8>>=
matplot(Y_result_n, ylab="Predykcja")
abline(v=c(10,20), lty=2, col="grey")
legend(x="top", legend=paste(1:3,levels(Species)), col=1:3, text.col=1:3)
@
Na podstawie wykresu \ref{fig:result_test_new_plot} zauważamy, że dla nowego zbioru danych, klasy setosa oraz virginica nie dominują w sposób znaczny klasy versicolor. Wnioskujemy, że z tego też względu otrzymujemy znacznie lepszy rezultat dla modelu regresji. \\
Zbadamy jeszcze skuteczność estymatora dla zbioru treningowego: \ref{tab:result_train_new}.

<<result_train_new, echo=FALSE>>=
Y_result.train.n <- as.matrix(X_train_n) %*% B1

maks.ind.train.n <- apply(Y_result.train.n, 1, FUN=function(x) which.max(x))
prognozowane.etykietki.train.n <- klasy[maks.ind.train.n]
rzeczywiste.etykietki.train.n <- Y_train_n

conf_mtrx.train.n <- table(rzeczywiste.etykietki.train.n, prognozowane.etykietki.train.n)
rownames(conf_mtrx.train.n) <- c("setosa.true", "versicolor.true", "virginica.true")
kable(conf_mtrx.train.n, caption="Skuteczność nowego estymatora na zbiorze treningowym.", 
      format="latex")
@

Otrzymujemy zgodność na poziomie 96\%, zatem wnioskujemy, że model nie jest przetrenowany.

<<resutl_train_new_plot, echo=FALSE, fig.height=6, fig.width=8>>=
matplot(Y_result_n, ylab="Predykcja")
abline(v=c(40,80), lty=2, col="grey")
legend(x="top", legend=paste(1:3,levels(Species)), col=1:3, text.col=1:3)
@


\subsection{Podsumowanie.}
\begin{itemize}
\item Po przeprowadzeniu analiz wnioskujemy, iż model oparty na regresji liniowej jest skuteczny, kiedy zależności między zmiennymi są liniowe. Jak wiadomo, zazwyczaj jednak mamy styczność ze zmiennymi o zależnościach nieliniowych, gdzie estymator regresji może dawać niesatysfakcjonujące rezultaty. Widzimy, iż po dodaniu do zbioru danych cech wielomianowych stopnia 2, skuteczność klasyfikatora znacznie wzrasta
\item Ponadto, kiedy tworzymy model klasyfikacyjny dla większej liczby klas, regresja liniowa jest narażona na problem maskowania klas, który również wpływa niekorzystnie na wyniki estymatora.
\item Tworząc model regresji należy pamiętać o zapobiaganiu jego przetrenowania wykorzystując metody takie, jak \textit{cross-validation}  lub \textit{bagging}.
\end{itemize}
Podsumowując regresja liniowa zakłada, iż w zbiorze zmienne mają liniowe zależności. Pracując nad bardziej złożonym problemem klasyfikacyjnym, dla dużej liczby klas, wybór odpowiednich składników wielomianowych może być czasochłonne, a przez to nieefektywne. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% Zad. 2
<<>>=
library(mlbench)
library(ipred)
@

\section{Porównanie metod klasyfikacji}

\subsection{Opis danych}
<<>>=
data(Glass)
str(Glass)
# more info:
# https://archive.ics.uci.edu/ml/datasets/glass+identification
# 1. Id number: 1 to 214
# 2. RI: refractive index
# (unit measurement: weight percent in corresponding oxide, as are attributes 4-10)
# 3. Na: Sodium 
# 4. Mg: Magnesium
# 5. Al: Aluminum
# 6. Si: Silicon
# 7. K: Potassium
# 8. Ca: Calcium
# 9. Ba: Barium
# 10. Fe: Iron
# 11. Type of glass: (class attribute)
# -- 1 building_windows_float_processed
# -- 2 building_windows_non_float_processed
# -- 3 vehicle_windows_float_processed
# -- 4 vehicle_windows_non_float_processed (none in this database)
# -- 5 containers
# -- 6 tableware
# -- 7 headlamps
str(Vehicle)
@










%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Krótki opis zagadnienia}

W tym ćwiczeniu, mamy do czynienia ze zbiorem danych o odłamkach szkła.
<<przykladowe_dane, echo=FALSE>>=
kable(head(Glass), caption="Przykładowe dane", format="latex")
@
<<przykladowe_dane_pokaz ,eval=FALSE>>=
head(Glass)
@


Dane składają się z informacji, dotyczących 214 odłamków.
Każdy z rekordów składa się ze współczynnika załamania światła ({\verb+RI+})
oraz stężenia różnych pierwiastków (w odpowiadających tlenkach)
w badanych próbkach.
Oprócz tego, posiadamy informacje o typie szkła,
którego 
Łącznie, dla każdej próbki występuje 13 cech.
Ponadto, w zbiorze nie ma wartości brakujących.

CDN

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Opis eksperymentów/analiz}

Na pewno:
k-NN
drzewka
naiwny klasyfikator bayesowski


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Wyniki}

W tej części zamieszczamy uzyskane wyniki, w szczególności fragmenty R-kodów wraz z tabelami i wykresami.

<<>>=
set.seed(14052020)
n <- nrow(Glass)
indeksy.zbioru.uczacego <- sample(1:n,4/5*n)
zbior.uczacy <- Glass[indeksy.zbioru.uczacego,]
zbior.testowy <- Glass[-indeksy.zbioru.uczacego,]
@

\subsubsection{Metoda k-najbliższych sąsiadów}
<<>>=

model.knn <- ipredknn(Type ~ ., data=zbior.uczacy, k=5)
predykcje <- predict(model.knn, zbior.testowy, type="class")
macierz.konfuzji <- table(predykcje, zbior.testowy$Type)

poprawne.wyniki <- sum(diag(macierz.konfuzji))
blad.klasyfikacji <-  1 - poprawne.wyniki / nrow(zbior.testowy)

@

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Podsumowanie}
Najważniejsze wnioski, jakie udało się wysnuć na podstawie przeprowadzonych analiz/eksperymentów. Wnioski mogą być wypunktowane, tzn.:



Można by zacytować zbióóóóóóóóór danych
\end{document}

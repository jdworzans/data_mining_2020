\documentclass[12pt, a4paper]{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% dodatkowe pakiety LaTeX'a
\usepackage[OT4]{polski}
\usepackage[utf8]{inputenc}
\usepackage[top=2.5cm, bottom=2.5cm, left=2cm, right=2cm]{geometry}
\usepackage{graphicx}
\usepackage{float}
\usepackage[colorlinks=true, linkcolor=blue]{hyperref}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ustawienia globalne
<<ustawienia_globalne, echo=FALSE, eval=TRUE, warning=FALSE, results=FALSE, message=FALSE>>=
library(knitr)

# for installation see: https://github.com/vqv/ggbiplot
library(ggbiplot)
library(datasets)
library(pastecs)
library(ggcorrplot)
library(cluster)
library(MASS)
library(ggplot2)
library(ggpubr)
library(e1071)
library(plot3D)
library(xtable)
library(arules)
opts_chunk$set(fig.path='figure/', fig.align='center', fig.pos='H',fig.width=5, fig.height=4)
@


\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% strona tytulowa
\title{Raport nr 2}
\author{Emilia Kowal [249716], Jakub Dworzański [249703]}
\maketitle
\tableofcontents


\section{Dyskretyzacja cech ciągłych.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Krótki opis zagadnienia.}

W tej sekcji przyjrzymy się działaniu różnych metod dyskretyzacji nienadzorowanej wykorzystując w tym celu zbiór danych \textit{iris} z pakietu \textit{datasets}, który zawiera zestaw pomiarów kwiatów oraz informację o gatunku irysa. Na podstawie otrzymanych wyników postaramy się przeprowadzić analizę skuteczności algorytmów.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Opis eksperymentów/analiz}
Przedsięwzięcie rozpoczynamy od wyboru cech o najgorszych oraz najlepszych zdolnościach dyskryminacyjnych. Dla wybranych zmiennych stosujemy algorytmy:

\begin{itemize}
\item dyskretyzacja według równej szerokości przedziałów,
\item dyskretyzacja według równej częstości,
\item dyskretyzacja oparta na algorytmie k-means,
\item dyskretyzacja z przedziałami wyznaczonymi ręcznie.
\end{itemize}

Następnie dokonujemy porównania wyników z rzeczywistymi etykietami klas. Zbadamy również wpływ obserwacji odstających na powyższe algorytmy.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Wyniki}

\subsubsection{Przygotowanie danych. Podstawowe informacje o danych.}

<<read_data>>=
data(iris)
attach(iris)
@

Zbiór danych zawiera 150 obserwacji dotyczących 3 gatunków irysa: setosa, versicolor oraz virginica. Po wczytaniu danych do przestrzeni roboczej sprawdzamy poprawność typów zmiennych.
<<data_info, echo=FALSE>>=
kable(
  data.frame(
    zmienna=names(iris),
    typ=sapply(iris, typeof),
    pierwsze.wartosci=sapply(iris, function(x) paste0(head(x, n=4), collapse=", "))
  ), row.names=FALSE, col.names = c("Zmienna", "Typ zmiennej", "Pierwsze wartości"), caption="Opis danych", format="latex"
)
@
Na podstawie tabeli \ref{tab:data_info} widzimy, że wszystkie zmienne zostały wczytane poprawnie. Następnie sprawdzamy, czy w zbiorze znajdują się wartości brakujące.

<<missing_data>>=
sum(is.na(iris))
@

Widzimy, że w zbiorze \textit{iris} nie ma wartości brakujących.

\subsubsection{Analiza zdolności dyskryminacyjnych cech.}

W celu identyfikacji cech o najgorszych oraz najlepszych zdolnościach dyskryminacyjnych prezetujemy dane na wykresach pudełkowych i wykresach rozrzutu.

<<petal_len_box, echo=FALSE, fig.cap="Wykres pudełkowy dla zmiennej Petal.Length">>=
ggplot(iris, aes(x=Species, y=Petal.Length)) +
  geom_boxplot()
@

<<petal_width_box, echo=FALSE, fig.cap="Wykres pudełkowy dla zmiennej Petal.Width">>=
ggplot(iris, aes(x=Species, y=Petal.Width)) +
  geom_boxplot()
@

<<petal_len_width, echo=FALSE, fig.cap="Wykres rozrzutu dla zmiennych Petal.Width i Petal.Length">>=
ggplot(iris, aes(x=Petal.Width, y=Petal.Length, color=Species))+
  geom_point(size=3)
@

<<sepal_length_box, echo=FALSE, fig.cap="Wykres pudełkowy dla zmiennej Sepal.Length">>=
ggplot(iris, aes(x=Species, y=Sepal.Length)) +geom_boxplot()
@

<<sepal_width_box, echo=FALSE, fig.cap="Wykres pudełkowy dla zmiennej Sepal.Width">>=
ggplot(iris, aes(x=Species, y=Sepal.Width)) +geom_boxplot()
@

<<sepal_width_len, echo=FALSE, fig.cap="Wykres rorzutu dla zmiennych Sepal.Width i Sepal.Length">>=
ggplot(iris, aes(x=Sepal.Width, y=Sepal.Length, color=Species))+
  geom_point(size=4)
@

Na podstawie analizy wykresów \ref{fig:petal_len_box}, \ref{fig:petal_width_box} i \ref{fig:petal_len_width} możemy stwierdzić, iż cechy \textit{Petal.Length} oraz \textit{Petal.Width} wykazują najlepsze zdolności dyskryminacyjne, natomiast cechy \textit{Sepal.Length} oraz \textit{Sepal.Width} (wykresy: \ref{fig:sepal_length_box}, \ref{fig:sepal_width_box} i \ref{fig:sepal_width_len}) posiadają najgorsze zdolności dyskryminacyjne. \\
Algorytmy dyskretyzacji zastosujemy dla zmiennych Petal.Width oraz Sepal.Width.

\subsubsection{Porównanie nienadzorowanych metod dyskretyzacji.}

Dla zmiennej \textit{Petal.Width} otrzymujemy następujące wyniki:
<<pet_eq_wid_tab, echo=FALSE>>=
d <- iris[, "Petal.Width"]
d.disc.eq.width <- discretize(d, method = "interval", breaks=3)
tab.d.eq.width <- table(d.disc.eq.width, Species)
kable(
  as.data.frame.matrix(tab.d.eq.width), caption="Tabela kontyngencji dla dyskretyzacji Petal.Width metodą equal width.", format="latex"
)
@

<<pet_fixed_tab, echo=FALSE>>=
d.disc.fixed <- discretize(d, method="fixed", breaks=c(-Inf, 0.75, 1.65, Inf))
tab.d.fixed <- table(d.disc.fixed, Species)
kable(
  as.data.frame.matrix(tab.d.fixed), caption="Tabela kontyngencji dla dyskretyzacji Petal.Width metodą fixed.", format="latex"
)
@

<<pet_kmeans_tab, echo=FALSE>>=
d.disc.km.clus <- discretize(d, method="cluster", breaks=3)
tab.d.km.clus <- table(d.disc.km.clus, Species)
kable(
  as.data.frame.matrix(tab.d.km.clus), caption="Tabela kontyngencji dla dyskretyzacji Petal.Width metodą k-means.", format="latex"
)
@

<<pet_eq_freq_tab, echo=FALSE>>=
d.disc.eq.freq <- discretize(d, method="frequency", breaks=3)
tab.d.eq.freq <- table(d.disc.eq.freq, Species)
kable(
  as.data.frame.matrix(tab.d.fixed), caption="Tabela kontyngencji dla dyskretyzacji Petal.Width metodą equal frequency.", format="latex"
)
@



\begin{itemize}

\item dla dyskretyzacji według równych przedziałów (tabela: \ref{tab:pet_eq_wid_tab}), według przedziałów zadanych ręcznie (tabela: \ref{tab:pet_fixed_tab}) oraz wykorzystującej algorytm k-means (tabela: \ref{tab:pet_kmeans_tab}) dostajemy wynik o poziomie zgodności 96\%,
\item dla dyskretyzacji według równych częstości (tabela: \ref{tab:pet_eq_freq_tab}) otrzymujemy najgorszy wynik, współczynnik zgodności wynosi 94.67\%.
\end{itemize}

Porównujemy, na wykresach rozrzutu, wyniki poszczególnych algorytmów dyskretyzacji dla zmiennej \textit{Petal.Width}.

<<scatter_petal,fig.width=8, fig.height=7, echo=FALSE, message=FALSE, fig.cap="Wyniki dyskretyzacji dla zmiennej Petal.Length">>=
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  require(grid)
  
  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)
  
  numPlots = length(plots)
  
  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                     ncol = cols, nrow = ceiling(numPlots/cols))
  }
  
  if (numPlots==1) {
    print(plots[[1]])
    
  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
    
    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
      
      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
y <- runif(length(d))
df_pet_plot <- cbind(data.frame(d,y), Species)


breaks.equal.width <- attributes(d.disc.eq.width)$"discretized:breaks"
p1 <- ggplot(df_pet_plot, aes(x=d, y=y, color=Species)) +
  geom_point() + geom_vline(xintercept = breaks.equal.width) +
  ggtitle("Equal width.") + 
  xlab("Petal.Width")


breaks.equal.freq <- attributes(d.disc.eq.freq)$"discretized:breaks"
p2 <- ggplot(df_pet_plot, aes(x=d, y=y, color=Species)) +
  geom_point() + geom_vline(xintercept = breaks.equal.freq) +
  ggtitle("Equal frequency.") + 
  xlab("Petal.Width")



breaks.kmeans <- attributes(d.disc.km.clus)$"discretized:breaks"
p3 <- ggplot(df_pet_plot, aes(x=d, y=y, color=Species)) +
  geom_point() + geom_vline(xintercept =breaks.kmeans) +
  ggtitle("K-means.") + 
  xlab("Petal.Width")


breaks.fixed <- attributes(d.disc.fixed)$"discretized:breaks"
p4 <- ggplot(df_pet_plot, aes(x=d, y=y, color=Species)) +
  geom_point() + geom_vline(xintercept =breaks.fixed) +
  ggtitle("Fixed.") + 
  xlab("Petal.Width")

multiplot(p1, p2, p3, p4, cols=2)
@
Widzimy na wykresach rozrzutu, że dla zmiennej \textit{Petal.Width} o najlepszych zdolnościach dyskryminacyjnych, przedziały wyznaczone przez zastosowane algorytmy, pozwalają nam z dużym przybliżeniem określić, do której z klas należy dana próba.

Dla zmiennej \textit{Sepal.Width}, o słabych zdolnościach dyskryminacyjnych, otrzymujemy następujące wyniki:
<<sep_eq_wid_tab, echo=FALSE>>=
x <- iris[, "Sepal.Width"]
x.disc.eq.width <- discretize(x, method = "interval", breaks=3)
tab.x.eq.width <- table(x.disc.eq.width, Species)
kable(
  as.data.frame.matrix(tab.x.eq.width), caption="Tabela kontyngencji dla dyskretyzacji Sepal.Width metodą equal width.", format="latex"
)
@

<<sep_fixed_tab, echo=FALSE>>=
x.disc.fixed <- discretize(x, method="fixed", breaks=c(-Inf, 2.75, 3.45, Inf))
tab.x.fixed <- table(x.disc.fixed, Species)
kable(
  as.data.frame.matrix(tab.x.fixed), caption="Tabela kontyngencji dla dyskretyzacji Sepal.Width metodą fixed.", format="latex"
)
@

<<sep_kmeans_tab, echo=FALSE>>=
x.disc.km.clus <- discretize(x, method="cluster", breaks=3)
tab.x.km.clus <- table(x.disc.km.clus, Species)
kable(
  as.data.frame.matrix(tab.x.km.clus), caption="Tabela kontyngencji dla dyskretyzacji Sepal.Width metodą k-means.", format="latex"
)
@

<<sep_eq_freq_tab, echo=FALSE>>=
x.disc.eq.freq <- discretize(x, method="frequency", breaks=3)
tab.x.eq.freq <- table(x.disc.eq.freq, Species)
kable(
  as.data.frame.matrix(tab.x.fixed), caption="Tabela kontyngencji dla dyskretyzacji Sepal.Width metodą equal frequency.", format="latex"
)
@

\begin{itemize}

\item dla dyskretyzacji wykorzystującej algorytm k-means (tabela: \ref{tab:sep_kmeans_tab}) dostajemy najwyższy współczynnik zgodności-56\%,
\item dla dyskretyzacji według równych częstości (tabela: \ref{tab:sep_eq_freq_tab}) otrzymujemy zgodność na poziomie 55.33\%,
\item  dla dyskretyzacji metodą fixed (tabela: \ref{tab:sep_fixed_tab}) dostajemy zgodność: 52.67\%,
\item najgorszy wynik obserwujemy dla dyskretyzacji według równych przedziałów (tabela \ref{tab:sep_eq_wid_tab}. Współczynnik zgodności wynosi 50.67\%.
\end{itemize}

Porównujemy, na wykresach rozrzutu, wyniki poszczególnych algorytmów dyskretyzacji dla zmiennej \textit{Sepal.Width}.

<<scatter_sepal, fig.width=8, fig.height=7, echo=FALSE, fig.cap="Wyniki dyskretyzacji dla zmiennej Sepal.Length">>=
df_sep_plot <- cbind(data.frame(x,y), Species)


breaks.equal.width1 <- attributes(x.disc.eq.width)$"discretized:breaks"
p5 <- ggplot(df_sep_plot, aes(x=x, y=y, color=Species)) +
  geom_point() + geom_vline(xintercept = breaks.equal.width1) +
  ggtitle("Equal width.") + 
  xlab("Sepal.Width")


breaks.equal.freq1 <- attributes(x.disc.eq.freq)$"discretized:breaks"
p6 <- ggplot(df_sep_plot, aes(x=x, y=y, color=Species)) +
  geom_point() + geom_vline(xintercept = breaks.equal.freq1) +
  ggtitle("Equal frequency.") + 
  xlab("Sepal.Width")



breaks.kmeans1 <- attributes(x.disc.km.clus)$"discretized:breaks"
p7 <- ggplot(df_sep_plot, aes(x=x, y=y, color=Species)) +
  geom_point() + geom_vline(xintercept =breaks.kmeans1) +
  ggtitle("K-means.") + 
  xlab("Sepal.Width")


breaks.fixed1 <- attributes(x.disc.fixed)$"discretized:breaks"
p8 <- ggplot(df_sep_plot, aes(x=x, y=y, color=Species)) +
  geom_point() + geom_vline(xintercept =breaks.fixed1) +
  ggtitle("Fixed.") + 
  xlab("Sepal.Width")

multiplot(p5, p6, p7, p8, cols=2)
@
Również na wykresie rozrzutu dla dyskretyzacji według równych przedziałów można dostrzec, że algorytm, w porównaniu do pozostałych trzech, poradził sobie najgorzej ze zmienną \textit{Sepal.Width}.

\subsubsection{Wpływ wartości odstających na metody dyskretyzacji.}

Analizę zmiennej Petal.Width powtarzamy, zastępując wartość najmniejszą oraz największą cechy, wartościami odstającymi.

<<petal_width_outliers>>=
d1 <- Petal.Width
d1[which.min(d1)] <- min(d1) - 2*IQR(d1)
d1[which.max(d1)] <- max(d1) + 2*IQR(d1)
@

<<pet_modified_eq_wid, echo=FALSE>>=
d1.disc.eq.width <- discretize(d1, method = "interval", breaks=3)
tab.d1.eq.width <- table(d1.disc.eq.width, Species)
kable(
  as.data.frame.matrix(tab.d1.eq.width), caption="Tabela kontyngencji dla dyskretyzacji metodą equal frequency zmodyfikowanej Petal.Width.", format="latex"
)
@
Obecność wartości odstających znacząco wpływa na dyskretyzację według równych przedziałów. Dla transformacji przeprowadzonej na zmodyfikowanej zmiennej Petal.Width otrzymujemy zgodność 34.67\% (tabela: \ref{tab:pet_modified_eq_wid}), czyli aż o 61,33 punkta procentowego mniejszą od wyniku dla Petal.Width bez wartości odstających.

<<outliers_petal_eq_width_plot, echo=FALSE, fig.cap="Dyskretyzacja equal width dla Petal.Width z wartościami odstającymi.">>=
df_sep_plot <- cbind(data.frame(d1,y), Species)
breaks.equal.freq.outliers<- attributes(d1.disc.eq.width)$"discretized:breaks"

ggplot(df_sep_plot, aes(x=x, y=y, color=Species)) +
  geom_point() + geom_vline(xintercept =breaks.kmeans1) +
  ggtitle("Dyskretyzacja equal width.") + 
  xlab("Petal.Width")
@
Widzimy na wykresie, iż wartości krańców przedziałów zostały zdeterminowane przez wartości odstające zmiennej \textit{Petal.Width}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Podsumowanie}

Przeprowadzone eksperymenty pozwalają nam dostrzec, iż niezwykle ważnym dla przeprowadzenia dyskretyzacji, jest dokładna analiza zdolności dyskryminacyjnych zmiennych. Wnioskujemy, iż dla rozkładów ciężkoogonowych nie stosujemy dyskretyzacji opartej na równych przedziałach, wrażliwej na wartości odstające. Dla zbioru iris, na podstawie cechy \textit{Petal.Width}, jesteśmy w stanie określić z dużą dokładnością, do której grupy przynależy dana próba.




\section{Analiza składowych głównych (Principal Component Analysis (PCA))}
\subsection{Krótki opis zagadnienia}

Celem tego ćwiczenia będzie przede wszystkim zaznajomienie się z algorytmem PCA
oraz ocena jego przydatności. Sprawdzimy jakie możliwości redukcji wymiaru dostarcza
i jak wiele informacji jesteśmy w stanie, dzięki niemu, zachować po przeksztalceniu danych
do mniejszych wymiarów.

\subsection{Opis eksperymentów/analiz}

Posłużymy się zbiorem {\verb+state.x77+} z pakietu {\verb+datasets+}. Dane te zawierają podstawowe informacje
o każdym ze stanów. Po przekształceniu danych przy pomocy PCA, przeanalizujemy je w nowej postaci.
Na początku sprawdzimy jak wiele całkowitej wariancji wyjaśniają poszczególne główne składowe,
a następnie przeanalizujemy wizualnie dane w nowej postaci. Poza tym, posługując się wektorami ładunków,
dwuwykresem oraz macierzą korelacji postaramy się zdobyć więcej informacji o zależnościach między zmiennymi.

\subsection{Wyniki}
<<pca_inicjalizacja, echo=FALSE, message=FALSE>>=

dane <- as.data.frame(state.x77)
@

<<pca_przykladowe_dane, echo=FALSE>>=
kable(head(dane), caption="Przykładowe dane", format="latex")
@
<<pca_wstep_widok, eval=FALSE>>=
head(dane)
ggplot(stack(dane), aes(x=ind, y=values)) + geom_boxplot()
@

<<pca_boxplot, echo=FALSE, fig.cap="Wykresy pudełkowe zmienności poszczególnych zmiennych ze zbiory danych.">>=
ggplot(stack(dane), aes(x=ind, y=values)) + geom_boxplot() + labs(y="Wartości", x="Zmienne")
@

W tabeli \ref{tab:pca_przykladowe_dane} widzimy przykładowe dane. Na podstawie wykresu \ref{fig:pca_boxplot} możemy
stwierdzić, że przed zastosowaniem PCA, będziemy musieli dokonać standaryzacji danych, ponieważ zmienna
{\verb+Area+} dominuje wariancję wszystkich zmiennych.

Dlatego też standaryzujemy dane i wyznaczamy składowe główne.
<<pca_pca>>=
dane.pca <- prcomp(dane, retx=T, center=T, scale.=T)
@

Teraz możemy zbadać rozrzut składowych głównych.

<<pca_pc_boxplot, fig.cap="Analiza rozproszenia składowych głównych.">>=
pc <- data.frame(dane.pca$x)
ggplot(stack(pc), aes(x=ind, y=values)) + geom_boxplot() +
  labs(x="Składowe główne", y="Wartości")
@

Korzystając z wykresu \ref{fig:pca_pc_boxplot}, możemy zauważyć, że
dla zmiennej PC1 rozstęp międzykwartylowy ma największą wartość.

Dla pierwszych czterech głównych składowych, przeanalizujemy wektory ładunków.
<<pca_ladunki_widok, eval=FALSE>>=
dane.pca$rotation[,1:4]
@
<<pca_ladunki, echo=FALSE>>=
kable(dane.pca$rotation[,1:4], caption="Wektory ładunków dla składowych głównych PC1, PC2, PC3, PC4.", format="latex")
@

W tabeli \ref{tab:pca_ladunki} możemy zobaczyć, że:
\begin{itemize}
  \item{
  I wektor ładunków przypisuje w przybliżeniu jednakową wagę zmiennym:
  {\verb+Illiteracy+}, {\verb+Life Exp+}, {\verb+Murder+} oraz {\verb+HS Grad+},
  zatem PC1 można interpretować
  jako wskaźnik poziomu edukacji oraz długości życia i popełnionych morderstw.
  }
  \item{
  II wektor ładunków przypisuje największe wagi dla zmiennych 
  {\verb+Area+}, {\verb+Income+}, {\verb+Population+}, czyli PC2 można uznać za wskaźnik zaludnienia 
  oraz wysokości zarobków na danym obszarze.
  }
  \item{
  III wektor ładunków przypisuje największą wagę zmiennej {\verb+Population+} oraz {\verb+Area+},
  zatem opisuje poziom zaludnienia.
  }
  \item{
  IV wektor ładunków przypisuje największą wagę zmiennej {\verb+Frost+}, zatem wskazuje
  na częstość występowania mrozów w danym stanie
  }
\end{itemize}

Kiedy już mamy wstępne informacje, możemy przeanalizować, jaki procent wyjaśnionej wariancji odpowiada
poszczególnym składowym głównym.
<<pca_zmiennosc_widok, eval=FALSE>>=
summary(dane.pca)
wariancja <- (dane.pca$sdev ^2)/sum(dane.pca$sdev^2)
kum.wariancja <- cumsum(wariancja)
df_zmiennosc <- data.frame(wariancja, kum.wariancja, names(pc))

ggplot(df_zmiennosc, aes(x=names.pc., y=wariancja)) +
  geom_bar(stat='identity')
ggplot(df_zmiennosc, aes(x=names.pc., y=kum.wariancja)) +
  geom_bar(stat='identity')
@

<<pca_zmiennosc, echo=FALSE>>=
pca.podsumowanie <- data.frame(summary(dane.pca)$importance)
row.names(pca.podsumowanie) <- c(
  "Odchylenie standardowe", "Część całkowitej wariancji", "Skumulowana część całkowitej wariancji"
)
kable(pca.podsumowanie, format="latex", digits = 2, caption="Udział głównych składowych w całkowitej wariancji.")
@

<<pca_zmiennosc_wykres, echo=FALSE, fig.cap="Procent zmienności oraz kumulatywnej zmienności dla poszczególnych składowych.", fig.width=6>>=
wariancja <- (dane.pca$sdev ^2)/sum(dane.pca$sdev^2)
kum.wariancja <- cumsum(wariancja)
df_zmiennosc <- data.frame(wariancja, kum.wariancja, names(pc))

# udział wyjaśnionej wariancji: scree plot
ggarrange(
ggplot(df_zmiennosc, aes(x=names.pc., y=wariancja)) + 
  labs(x="Składowe główne", y="Wariancja (%)") +
  ylim(0, 1) +
  geom_bar(stat='identity'),
ggplot(df_zmiennosc, aes(x=names.pc., y=kum.wariancja)) + 
  labs(x="Składowe główne", y="Kumulatywna wariancja (%)") +
  geom_bar(stat='identity') +
  geom_hline(yintercept = c(0.8, 0.9), color="red") +
  scale_y_continuous(breaks=c(0.00, 0.25, 0.50, 0.75, 0.80, 0.90, 1.00),
                     labels=c("0.00", "0.25", "0.50", "0.75", "0.80", "0.90", "1.00"))
)
@


W tabeli \ref{tab:pca_zmiennosc} oraz na wykresie \ref{fig:pca_zmiennosc_wykres} widzimy jaki procent
całkowitej zmienności odpowiada poszczególnym składowym. Ponadto widzimy, że do wyjaśnienia ponad 80\% wariancji
wystarczą cztery pierwsze główne składowe, a pierwsze pięć składowych wyjaśnia ponad 90\% całkowitej wariancji.

Teraz sprawdzimy, jak dobrze działa PCA poprzez wizualizację danych, czyli dla pierwszych trzech składowych głównych.
<<pca_wykres_2d_widok, eval=FALSE>>=
dane.PCA <- data.frame(dane.pca$x)
ggplot(dane.PCA, aes(x=PC1, y=PC2, col=state.region, label=state.abb)) +
  geom_text()
@

<<pca_wykres_2d, echo=FALSE, fig.cap="Wykres rozrzutu dwóch pierwszych składowych głównych.">>=
dane.PCA <- data.frame(dane.pca$x)
ggplot(dane.PCA, aes(x=PC1, y=PC2, col=state.region, label=state.abb)) + geom_text() +
  labs(col="Region")
@

<<pca_3d_pokaz, eval=FALSE>>=
attach(dane.PCA)
points3D(PC1, PC2, PC3)
@


<<pca_3d, echo=FALSE, fig.cap="Wykres rozrzutu trzech pierwszych składowych głównych.">>=
scatter3D(dane.PCA$PC1, dane.PCA$PC2, dane.PCA$PC3, colvar=as.integer(state.region), col=rainbow(4), bty="g",
          colkey=list(
            at=c(1, 2, 3, 4), labels=c("Northeast", "South", "North Central", "West"),
            side=1
          ), theta=120
)
@

Na podstawie wykresów \ref{fig:pca_wykres_2d} i \ref{fig:pca_3d}, możemy powiedzieć, że wśród danych poza
wartościami odstającymi od reszty(przede wszystkim Alaska, ale też California, Texas, Nowy York i Florida),
możemy wyszczególnić dwie grupy. Mniejsza z nich, to dość jednolita grupa, która składa się z
większości południowych stanów. Reszta stanów zdaje się układać w dość zróżnicowaną grupę.

Widzimy również, że po przekształceniu otrzymaliśmy kilka stanów odstających od pozostałych.
Przyczyny odseparowania Alaski można szukać mięzdy innymi w nieporównywalnie dużej powierzchni tego stanu.

Zbadamy dokładniej przedstawienie zmiennych w dwuwymiarowej przestrzeni.

<<pca_biplot_widok, eval=FALSE>>=
ggbiplot(dane.pca, groups=state.region, labels=state.abb)
@
<<pca_biplot, echo=FALSE, fig.cap="Dwuwykres dla zbioru danych po przekształceniu PCA.">>=
ggbiplot(dane.pca, scale=0, groups=state.region, labels.size=3, labels=state.abb) +
  labs(x="PC1", y="PC2", col="Region")
@

Istotnie, korzystając z wykresu \ref{fig:pca_biplot}, widzimy, że wektor reprezentujący wzrost zmiennej
{\verb+Area+} jest skierowany w stronę Alaski.

Teraz postaramy się zbadać korelację pomiędzy zmiennymi na podstawie dwuwykresu oraz macierzy korelacji.

<<pca_corr_matrix_widok, eval=FALSE>>=
ggcorrplot(cor(dane))
@
<<pca_corr_matrix, echo=FALSE, fig.cap="Macierz korelacji">>=
ggcorrplot(cor(dane), colors=c("steelblue","white","darkred"), lab=T)
@

Na dwuwykresie (Rys. \ref{fig:pca_biplot}),
możemy zauważyć, że wskaźnik morderstw może być skorelowany z analfabetyzmem.
Ponadto, co wydaje się być dość intuicyjne, wskaźnik morderstw wygląda na ujemnie skorelowany
z oczekiwaną długością życia. Ponadto, z wykresu wynika, że wskaźnik mroźnych dni w ciągu roku jest
skorelowany z oczekiwaną długością życia i negatywnie skorelowany ze wskaźnikiem morderstw.
Widać również, że populacja jest skorelowana z powierzchnią stanu, a procent wyższego wykształcenia
jest skorelowany z przychodem.

Korzystając z macierzy korelacji (Rys. \ref{fig:pca_corr_matrix}),
możemy zauważyć, że większość z naszych przewidywań jest słuszna.
Należy jednak zaznaczyć, że współczynnik korelacji między ilością mroźnych dni, a oczekiwaną długością życia,
jest niższy, niż moglibyśmy tego oczekiwać, po spojrzeniu na dwuwykres. Ponadto, widzimy, że wbrew dwuwykresowi,
współczynnik korelacji pomiędzy powierzchnią stanu, a populacją jest bardzo bliski 0.

\subsection{Podsumowanie}

Widzimy, że algorytm PCA pozwolił na przystępne i łatwe w wizaualizacji przedstawienie zbioru danych.
Ponadto, zobaczyliśmy, że już trzy pierwsze składowe główne wyjaśniają 79\% całkowitej wariancji.
Należy pamiętać, że do przeprowadzenie PCA, konieczna było standaryzacja danych.
Ciekawym wynikiem jest to, że w danych został odzwierciedlony podział północ-południe.
Warto również zapamiętać, że podczas analizy otrzymaliśmy kilka charakterystycznych stanów, które reprezentują
szczególne cechy (przede wszystkim Alaska).

Dlatego też, możemy ocenić pozytywnie przydatność algorytmu PCA do analizy danych.
Znaczna redukcja wymiaru pozwoliła jednocześnie zachować dość dużo informacji o danych.

\section{Skalowanie wielowymiarowe (Multidimensional Scaling (MDS))}
\subsection{Krótki opis zagadnienia}
W tej części będziemy się zajmowali MDS, czyli skalowaniem wielowymiarowym.
Zdecydowaliśmy się na zbadanie skalowania niemetrycznego, które jest wariantem MDS.


\subsection{Opis eksperymentów/analiz}

Będziemy sprawdzali jakość odwzorowania MDS.
W tym celu zbadamy, jak zmieniają się wartości funkcji {\verb+STRESS+} oraz diagramy Shepparda dla różnych wymiarów docelowej przestrzeni. Do badań wykorzystamy zbiór danych, dotyczący pasażerów Titanica.

\subsection{Wyniki}

<<mds_inicjalizacja, echo=FALSE, message=FALSE>>=

# Kaggle titanic dataset from https://www.kaggle.com/heptapod/titanic
dane <- read.csv("titanic.csv")
titanic.dane <- subset(dane, select=c(Pclass,Sex,Age,sibsp,Parch,Fare,Embarked))
titanic.dane$Survived <- factor(dane$X2urvived, levels=c(0, 1), labels=c("N", "Y"))

titanic.dane$Pclass <- as.ordered(titanic.dane$Pclass)
titanic.dane$Sex <- factor(titanic.dane$Sex, levels=c(0, 1), labels=c("M","F"))
titanic.dane$Embarked <- as.factor(titanic.dane$Embarked)
titanic.dane <- na.omit(titanic.dane)

titanic.dane.mds <- subset(titanic.dane, select=-c(Survived))

unikatowe <- !duplicated(titanic.dane.mds)
titanic.dane <- titanic.dane[unikatowe,]
titanic.dane.mds <- titanic.dane.mds[unikatowe,]
@

<<mds_przykładowe_dane, echo=FALSE>>=
kable(head(titanic.dane), caption="Przykładowe dane", format="latex")
@
<<eval=FALSE>>=
head(titanic.dane)
@

W tabeli \ref{tab:mds_przykładowe_dane}, przedstawiającej przykładowe dane, możemy zobaczyć, że wśród zmiennych występują nie tylko cechy numeryczne, takie jak wiek({\verb+Age+}),
ale również cechy kategoryczne, w tym:
\begin{itemize}
  \item płeć({\verb+Sex+}), jako zmienna binarna,
  \item port({\verb+Fare+}), w którym pasażer wszedł na pokład statku, jako zmienna nominalna,
  \item klasę({\verb+Pclass+}), którą podróżował pasażer, jako zmienna uporządkowana.
\end{itemize}
Ponadto w danych istnieje zmienna grupująca {\verb+Survived+}, która informuje o tym, czy pasażer przeżył katastrofę.

Do dalszej analizy będziemy wykorzystywać dane bez zmiennej grupującej, aby później na jej podstawie ocenić jakość odwzorowania.
<<eval=FALSE>>=
titanic.dane.mds <- subset(titanic.dane, select=-c(Survived))
@

W kolejnych krokach, aby dokonać skalowania, będziemy potrzebować odmienności między wektorami cech.
<<mds_macierz_odmienności>>=
macierz.odmiennosci <- as.matrix(daisy(
  titanic.dane.mds,
  stand=TRUE
))
@

Dysponując macierzą odmienności, możemy zbadać jak zmieniają się diagramy Shepparda oraz wartość funkcji kryterialnej {\verb+STRESS+}, wraz ze zmianą wymiaru docelowej przestrzeni.
Dlatego teraz wyznaczamy {\verb+STRESS+} oraz diagram Shepparda dla k=1,2,\ldots,7.

<<mds_funkcja_do_badań_do_pokazania, eval=FALSE>>=
badanie.MDS <- function (k.max, macierz.odmiennosci) {
  STRESS <- numeric(k.max)
  wykresy <- list()
  for (k in 1:k.max) {
    mds <- isoMDS(macierz.odmiennosci, k=k)
    STRESS[k] <- mds$stress
    odleglosci.k <- as.matrix(dist(mds$points, method="euclidean"))
    wykresy[[k]] <- ggplot() + geom_point(aes(x=c(macierz.odmiennosci), y=c(odleglosci.k)))
  }
  return(list(wykresy=wykresy, STRESS=STRESS))
}
k.max <- length(titanic.dane.mds)
wyniki <- badanie.MDS(k.max, macierz.odmiennosci)
@

<<mds_funkcja_do_badań, results=FALSE, echo=FALSE>>=
badanie.MDS <- function (k.max, macierz.odmiennosci) {

  STRESS <- numeric(k.max)
  wykresy <- list()
  
  for (k in 1:k.max) {
    mds <- isoMDS(macierz.odmiennosci, k=k)
    STRESS[k] <- mds$stress

    odleglosci.k <- as.matrix(dist(mds$points, method="euclidean"))
    indeksy <- sample(1:length(c(macierz.odmiennosci)), size=10000)
    wykresy[[k]] <- ggplot() +
      geom_point(
        aes(x=c(macierz.odmiennosci)[indeksy], y=c(odleglosci.k)[indeksy]),
        alpha=0.05
      ) +
      labs(
        title=paste("k=", k, sep=""),
        x="orginalne odległości",
        y="nowe odległości"
      )
  }
  return(
    list(wykresy=wykresy, STRESS=STRESS)
  )
}
k.max <- length(titanic.dane.mds)
wyniki <- badanie.MDS(k.max, macierz.odmiennosci)
@

<<mds_wykres_STRESS_do_pokazania, eval=FALSE>>=
ggplot() + geom_line(aes(x=1:k.max, y=wyniki$STRESS))
@

<<mds_wykres_STRESS, fig.cap="Zależność funkcji kryterialnej STRESS od docelowego wymiaru", echo=FALSE>>=
ggplot() +
  geom_line(aes(x=1:k.max, y=wyniki$STRESS), linetype="dashed") +
  geom_point(aes(x=1:k.max, y=wyniki$STRESS), size=2.5) +
  labs(x="Docelowy wymiar", y="STRESS")
@

Na wykresie \ref{fig:mds_wykres_STRESS} widzimy, że funkcja {\verb+STRESS+} maleje z każdym zwiększeniem wymiaru docelowego. Na jego podstawie, możemy również stwierdzić, że dla w przestrzeni dwuwymiarowej przyjmuje ona stosunkowo duże wartości, co wskazuje na potencjalnie dużą utratę informacji. Widzimy również, że także w przestrzeni trójwymiarowej występuje utrata informacji, jednak jest ona znacznie mniejsza, niż dla $k=2$. Stąd, możemy przypuszczać, że dzięki wykorzystaniu metod wizualizacji 3D, będziemy mogli poznać strukturę zbioru danych znacznie lepiej, niż na standardowym, dwuwymiarowym wykresie.

<<mds_diagramy_shepparda, fig.cap="Diagramy Shepparda", fig.height=8>>=
wykresy <- wyniki$wykresy
ggarrange(plotlist=wykresy[c(2, 4, 6)], nrow=3)
@

Diagramy Shepparda, które przedstawiają porównanie odległości między orginalną, a docelową przestrzeną, nie przedstawiają istotnych zmian między docelowymi wymiarami. Dlatego też, korzystając przede wszystkim z wykresu funkcji {\verb+STRESS+}, jako docelowy wymiar przestrzeni, wybrałbym 4, ponieważ wykres zaczyna się w tym miejscu wypłaszczać, a jednocześnie pozwala on na wizualne badanie elementów zbioru poprzez wprowadzenie koloru lub kształtu, reprezentującego czwartą współrzędną
w tej przestrzeni.

Teraz spróbujemy ocenić jakość odwzorowań, korzystając z dodatkowej informacji, jaką jest zmienna grupująca {\verb+Survived+}.

<<mds_wizualizacja_2d_do_pokazania, eval=FALSE>>=
mds.k2 <- isoMDS(macierz.odmiennosci, k=2)
reprezentacja.mds.k2 <- data.frame(mds.k2$points)

ggplot(reprezentacja.mds.k2, aes(x=X1, y=X2)) +
  geom_point(aes(col=...))
@


<<mds_wizualizacja_2d, fig.cap="Wykres po odwzorowaniu MDS dla $k=2$ z podzialem na grupy", results=FALSE, echo=FALSE>>=
mds.k2 <- isoMDS(macierz.odmiennosci, k=2)
reprezentacja.mds.k2 <- data.frame(mds.k2$points)
ggarrange(
  ggarrange(
    ggplot(reprezentacja.mds.k2, aes(x=X1, y=X2)) +
    geom_point(aes(col=titanic.dane$Sex)) +
    labs(col="Płeć"),
    ggplot(reprezentacja.mds.k2, aes(x=X1, y=X2)) +
    geom_point(aes(col=titanic.dane$Pclass)) +
    labs(col="Klasa")
  ),
  ggplot(reprezentacja.mds.k2, aes(x=X1, y=X2)) +
    geom_point(aes(col=titanic.dane$Survived)) +
    labs(col="Przeżycie") +
    scale_color_manual(values=c("red", "blue")),
  nrow=2
)
@

Widzimy, że po odwzorowaniu można wyróżnić dwie grupy, które rodzielają dane ze względu na płeć pasażera.
Grupy te nie rozdzielają jednak danych ze względu na informację dotycząca tego, czy pasażer przeżył.
Możemy jednak zauważyć, że istotnie wśród kobiet odsetek przeżycia jest dużo wyższy.
Stąd, po sprawdzeniu, jak prezentuje się ich rozkład:

<<mds_plec_przezyce_widok, eval=FALSE>>=
table(titanic.dane$Sex, titanic.dane$Survived)
@
<<mds_plec_przezycie, echo=FALSE>>=
kable(table(titanic.dane$Sex, titanic.dane$Survived), caption="Tabela kontygencji dla podziału płeć-przeżycie", format="latex")
@
W tabeli \ref{tab:mds_plec_przezycie} widzimy, że faktycznie, przypisując tym dwóm grupom odpowiednią klasę grupującą, otrzymalibyśmy skuteczność na poziomie $71.59\%$. Stąd możemy powiedzieć, że dane po MDS wciąż zachowują dość dużo informacji.

Ponadto, na wykresie \ref{tab:mds_plec_przezycie} widzimy, że w danych pozostał dość dobry podział ze względu
na klasę, którą podróżował pasażer.

Teraz, możemy sprawdzić, czy przekształcenie MDS do przestrzeni trojwymiarowej będzie zawierało więcej informacji.
<<mds_3d, results=FALSE>>=
mds.k3 <- isoMDS(macierz.odmiennosci, k=3)
attach(data.frame(mds.k3$points))
@

<<mds_3d_wizualizacja_do_pokazania, eval=FALSE>>=
points3D(X1,X2,X3,...)
@

<<mds_3d_port, fig.cap="Wykres po odwzorowaniu MDS dla $k=3$ z podzialem na początek podróży", echo=FALSE>>=
points3D(X1,X2,X3,colvar=as.numeric(titanic.dane$Embarked),labels=c("X1", "X2", "X3"),bty="g",
         col=c("#1B9E77", "#D95F02", "#7570B3"), colkey=list(at=c(1,2,3), labels=c("1", "2", "3")))
@

<<mds_3d_przezycie, fig.cap="Wykres po odwzorowaniu MDS dla $k=3$ z podziałem na przeżycie", echo=FALSE>>=
points3D(X1,X2,X3, bty="g",
         colvar=as.numeric(titanic.dane$Survived),labels=c("X1", "X2", "X3"),
         col=c("#1B9E77", "#D95F02"), colkey=list(at=c(1, 2), labels=c("N", "Y"))
)
@

Na wykresie \ref{fig:mds_3d_port} widzimy, że dodatkowy wymiar dostarcza nam informacji między innymi na temat
portu, w którym pasażer wsiadł na statek.

Nie jest to jednak wystarczające do separacji pasażerów, którzy przeżyli, od tych, którzy nie przeżyli
(Rys. \ref{fig:mds_3d_przezycie}).
Mimo tego, redukcja wymiaru zdecydowanie pomogła w wizualizacji i w lepszym zrozumieniu danych.

\subsection{Podsumowanie}

Na podstawie przeprowadzonego eksperymentu, możemy stwierdzić, że skalowanie wielowymiarowe
może być niezwykle pomocne podczas analizy danych. Mimo tego, że nie rozwiązało ono bezpośrednio
głównego problemu, który wiąże się z tym zbiorem danych, czyli predykcji przeżycia pasażerów, to
pozwoliło na przeanalizowanie danych w 2- i 3- wymiarowych przestrzeniach, co pozwoliło na sformułowanie
początkowych hipotez, które mogłyby posłużyć do dalszej analizy.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Podsumowanie}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}
